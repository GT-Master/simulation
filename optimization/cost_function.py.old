import numpy as np

import os
import warnings

import logging
logger = logging.getLogger(__name__)

import measurements.all.woa.data
import measurements.all.pw.data
from ndop.model.eval import Model

import util.io
import util.math.optimize



class Base:
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None, job_name_prefix=''):
        from ndop.model.constants import MODEL_PARAMETER_DIM
        from .constants import COST_FUNCTION_NODES_SETUP
        
        logger.debug('Initiating {} with {} years, {} tolerance, combination "{}", time step {}, df_accuracy_order {} and {} as job_nodes_max_file.'.format(self.__class__.__name__, years, tolerance, combination, time_step, df_accuracy_order, job_nodes_max_file))
        
        self.years = years
        self.tolerance = tolerance
        self.combination = combination
        self.time_step = time_step
        self.df_accuracy_order = df_accuracy_order
        
        job_setup = {'name': job_name_prefix, 'nodes_max': job_nodes_max_file, 'nodes_setup': COST_FUNCTION_NODES_SETUP}
#         self.model = Model(job_name_prefix=job_name_prefix, job_nodes_setup=COST_FUNCTION_NODES_SETUP, job_nodes_max_file=job_nodes_max_file)
        self.model = Model(job_setup)
        
        self.last_parameters_f = None
        self.last_parameters_df = None
        self.last_model_f = None
        self.last_model_df = None
    
    
    ## access to model
    def calculate_model_f(self, parameters):
        raise NotImplementedError("Please implement this method")
    
    def get_model_f(self, parameters):
        if self.last_model_f is not None and all(parameters == self.last_parameters_f):
            logger.debug('Returning cached model f.')
            model_f = self.last_model_f
        else:
            logger.debug('Calculating new model f.')
            model_f = self.calculate_model_f(parameters)
            self.last_parameters_f = parameters
            self.last_model_f = model_f
        
        return model_f
    
    
    def calculate_model_df(self, parameters):
        raise NotImplementedError("Please implement this method")
    
    def get_model_df(self, parameters):
        if self.last_model_df is not None and all(parameters == self.last_parameters_df):
            logger.debug('Returning cached model df.')
            model_df = self.last_model_df
        else:
            logger.debug('Calculating new model df.')
            model_df = self.calculate_model_df(parameters)
            self.last_parameters_df = parameters
            self.last_model_df = model_df
        
        return model_df
    
    
    ## access to cache
    def get_file(self, parameters, filename):
        from .constants import COST_FUNCTIONS_DIRNAME
        
        parameter_set_dir = self.model.get_parameter_set_dir(self.time_step, parameters, create=False)
        
        if parameter_set_dir is not None:
            cost_function_dir = os.path.join(parameter_set_dir, COST_FUNCTIONS_DIRNAME, self.__class__.__name__)
            os.makedirs(cost_function_dir, exist_ok=True)
            file = os.path.join(cost_function_dir, filename)
        else:
            file = None
        
        logger.debug('Got file {} for parameters {} and filename {}.'.format(file, parameters, filename))
        return file
    
    
    def load_file(self, parameters, filename):
        file = self.get_file(parameters, filename)
        if file is not None and os.path.exists(file):
            logger.debug('Loading values from {}.'.format(file))
            values = np.load(file)
        else:
            values = None
        return values
    
    def save_file(self, parameters, filename, values):
        file = self.get_file(parameters, filename)
        logger.debug('Saving values to {}.'.format(file))
        util.io.save_npy_and_txt(values, file)
    
    
    def matches_options(self, parameters, options_file):
        options = self.load_file(parameters, options_file)
        if options is not None:
            if options[2]:
                matches = options[0] >= self.years and options[1] <= self.tolerance
            else:
                matches = options[0] >= self.years or options[1] <= self.tolerance
            
            if len(options) == 4:
                matches = matches and options[3] >= self.df_accuracy_order
        else:
            matches = False
        
        return matches
        
    
    
    def calculate_f(self, parameters):
        raise NotImplementedError("Please implement this method")
    
    def f(self, parameters):
        from .constants import COST_FUNCTION_F_FILENAME, COST_FUNCTION_F_NORMALIZED_FILENAME, COST_FUNCTION_F_OPTION_FILENAME
        
        ## if matching load value
        if self.matches_options(parameters, COST_FUNCTION_F_OPTION_FILENAME):
            f = self.load_file(parameters, COST_FUNCTION_F_FILENAME)
            logger.debug('Cached f value {} loaded.'.format(f))
        ## else calculate and save value
        else:
            (f, f_normalized) = self.calculate_f(parameters)
            logger.debug('f value {} calculated and saving.'.format(f))
            self.save_file(parameters, COST_FUNCTION_F_FILENAME, f)
            self.save_file(parameters, COST_FUNCTION_F_NORMALIZED_FILENAME, f_normalized)
            options = (self.years, self.tolerance, self.combination == 'and')
            self.save_file(parameters, COST_FUNCTION_F_OPTION_FILENAME, options)
        
        return f
    
    
    def calculate_df(self, parameters):
        raise NotImplementedError("Please implement this method")
    
    def df(self, parameters):
        from .constants import COST_FUNCTION_DF_FILENAME, COST_FUNCTION_DF_OPTION_FILENAME
        
        ## if matching load value
        if self.matches_options(parameters, COST_FUNCTION_DF_OPTION_FILENAME):
            df = self.load_file(parameters, COST_FUNCTION_DF_FILENAME)
            logger.debug('Cached df value loaded.')
        ## else calculate and save value
        else:
            df = self.calculate_df(parameters)
            logger.debug('df value calculated and saving.')
            self.save_file(parameters, COST_FUNCTION_DF_FILENAME, df)
            options = (self.years, self.tolerance, self.combination == 'and', self.df_accuracy_order)
            self.save_file(parameters, COST_FUNCTION_DF_OPTION_FILENAME, options)
        
        return df
    



class WOA_Base(Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None, job_name_prefix=''):
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix=job_name_prefix)
        
        self.means = measurements.all.woa.data.means()
    
    
    def calculate_model_f(self, parameters):
        model_f = self.model.get_f_for_all(parameters, time_dim_desired=12, years=self.years, tolerance=self.tolerance, combination=self.combination, time_step=self.time_step)
        model_f = np.asanyarray(model_f)
        return model_f
    
    
    def calculate_model_df(self, parameters):
        model_df = self.model.get_df_for_all(parameters, time_dim_desired=12, years=self.years, tolerance=self.tolerance, combination=self.combination, time_step=self.time_step, accuracy_order=self.df_accuracy_order)
        model_df = np.asanyarray(model_df)
        model_df = np.swapaxes(model_df, 0, 1)
        return model_df



class WOA_OLS(WOA_Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix='WOA_OLS')
        
        nobs = measurements.all.woa.data.nobs()
        varis = measurements.all.woa.data.varis()
        mask = nobs > 0
        sum_of_variances = np.sum(varis[mask] / nobs[mask])
        self.normalization_factor = 1 / sum_of_variances
    
    
    def calculate_f(self, parameters):
        model_f = self.get_model_f(parameters)
        
        means = self.means
        
        f = np.nansum((means - model_f)**2)
        f_normalized = f * self.normalization_factor
        
        return (f, f_normalized)
    
    
    def calculate_df(self, parameters):
        model_f = self.get_model_f(parameters)
        model_df = self.get_model_df(parameters)
        
        means = self.means
        
        df_factors = means - model_f
        
        p_dim = len(parameters)
        df = np.empty(p_dim)
        
        for i in range(p_dim):
            df[i] = np.nansum(df_factors * model_df[i])
        
        df *= - 2
        
        return df



class WOA_WLS(WOA_Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        ## super init
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix='WOA_WLS')
        
        ## load data
        nobs = measurements.all.woa.data.nobs()
        varis = measurements.all.woa.data.varis()
        
        ## calculate variances
        inverse_variances = nobs / varis
        self.inverse_variances = inverse_variances
        
        ## calculate normalization factor
        number_of_total_measurements = (nobs > 0).sum()
        self.normalization_factor = 1 / number_of_total_measurements
    
    
    def calculate_f(self, parameters):
        model_f = self.get_model_f(parameters)
        
        means = self.means
        inverse_variances = self.inverse_variances
        
        f = np.nansum(inverse_variances * (means - model_f)**2)
        
        f_normalized = f * self.normalization_factor
        
        return (f, f_normalized)
    
    
    def calculate_df(self, parameters):
        model_f = self.get_model_f(parameters)
        model_df = self.get_model_df(parameters)
        
        means = self.means
        inverse_variances = self.inverse_variances
        
        df_factors = inverse_variances * (means - model_f)
        
        p_dim = len(parameters)
        df = np.empty(p_dim)
        
        for i in range(p_dim):
            df[i] = np.nansum(df_factors * model_df[i])
        
        df *= - 2 
        
        return df

    




class WOD_Base(Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None, job_name_prefix=''):
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix=job_name_prefix)
        
        points, values = measurements.all.pw.data.get_points_and_values()
        
        self.points = points
        self.values = values
    
    
    def calculate_model_f(self, parameters):
        model_f = self.model.get_f_for_points(parameters, self.points, years=self.years, tolerance=self.tolerance, combination=self.combination, time_step=self.time_step)
        return model_f
    
    
    def calculate_model_df(self, parameters):
        model_df = self.model.get_df_for_points(parameters, self.points, years=self.years, tolerance=self.tolerance, combination=self.combination, time_step=self.time_step, accuracy_order=self.df_accuracy_order)
        return model_df



class WOD_OLS(WOD_Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix='WOD_OLS')
        
        ## calculate sum of variance
        (dop_deviation, po4_deviation) = measurements.all.pw.data.get_deviation()
        sum_of_variance = 0
        for deviation in (dop_deviation, po4_deviation):
            sum_of_variance += np.sum(deviation**2)
        
        ## calculate normalization factor
        self.normalization_factor = 1 / sum_of_variance
    
    
    def calculate_f(self, parameters):
        model_f = self.get_model_f(parameters)
        
        values = self.values
        f = 0
        
        for tracer_index in range(len(values)):
            f += np.sum((values[tracer_index] - model_f[tracer_index])**2)
        
        f_normalized = f * self.normalization_factor
        
        return (f, f_normalized)
    
    
    def calculate_df(self, parameters):
        model_f = self.get_model_f(parameters)
        model_df = self.get_model_df(parameters)
        
        values = self.values
        
        p_dim = len(parameters)
        df = np.zeros(p_dim)
        
        for tracer_index in range(len(values)):
            df_factors = values[tracer_index] - model_f[tracer_index]
            for parameter_index in range(p_dim):
                df[parameter_index] += np.sum(df_factors * model_df[tracer_index][parameter_index])
        
        df *= - 2
        
        return df



class WOD_WLS(WOD_Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        ## super init
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix='WOD_WLS')
        
        ## calculate variance
        (dop_deviation, po4_deviation) = measurements.all.pw.data.get_deviation()
        self.variance = (dop_deviation**2, po4_deviation**2)
        
        ## calculate normalization factor
        number_of_total_measurements = sum(map(len, self.points))
        self.normalization_factor = 1 / number_of_total_measurements
        
    
    
    def calculate_f(self, parameters):
        model_f = self.get_model_f(parameters)
        
        values = self.values
        variance = self.variance
        f = 0
        
        for tracer_index in range(len(values)):
            f += np.sum((values[tracer_index] - model_f[tracer_index])**2 / variance[tracer_index])
        
        f_normalized = f * self.normalization_factor
        
        return (f, f_normalized)
    
    
    def calculate_df(self, parameters):
        model_f = self.get_model_f(parameters)
        model_df = self.get_model_df(parameters)
        
        values = self.values
        variance = self.variance
        
        p_dim = len(parameters)
        df = np.zeros(p_dim)
        
        for tracer_index in range(len(values)):
            df_factors = (values[tracer_index] - model_f[tracer_index]) / variance[tracer_index]
            for parameter_index in range(p_dim):
                df[parameter_index] += np.sum(df_factors * model_df[tracer_index][parameter_index])
        
        df *= - 2
        
        return df



class WOD_GLS(WOD_Base):
    
    def __init__(self, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        ## super init
        super().__init__(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file, job_name_prefix='WOD_GLS')
        
        ## load deviation
        (dop_deviation, po4_deviation) = measurements.all.pw.data.get_deviation()
        self.deviation = (dop_deviation, po4_deviation)
        
        ## calculate normalization factor
        number_of_total_measurements = sum(map(len, self.points))
        self.normalization_factor = 1 / number_of_total_measurements
        
        ## setup correlation bounds and last correlations
#         dim = 3
        dim = 2
        upper_bound = 1 - 10**(-5)
#         lower_bound = - upper_bound
        lower_bound = 0
        bounds = ((lower_bound, upper_bound),) * dim
        self.correlation_parameters_bounds = bounds
        
#         self.correlation_parameters_ineq_constraint = lambda x: x[0] * x[1] - x[2]**2 
#         self.correlation_parameters_ineq_constraints_jac = lambda x: (x[1], x[0], -2 * x[2])
        
        last = np.array((0.0,)*dim)
        self.last_correlation_parameters = last
    
    
    
    def f_for_cp_and_diff(self, correlation_parameters, diff_sum, diff_quad_sum):
        ## check input
        if not np.all(np.logical_and(correlation_parameters > -1, correlation_parameters < 1)):
            raise ValueError('Each correlation parameter have to be in (-1, 1), but they are {}.'.format(correlation_parameters))
        
        ## prepare input
        n = len(self.values[0])
        m = len(self.values[1])
        a = correlation_parameters[0]
        b = correlation_parameters[1]
#         c = correlation_parameters[2]
        c = 0
        
        ## calculate determinante of correlation matrix
        ln_det = (n-1)*np.log(1-a) + (m-1)*np.log(1-b) + np.log((1+(n-1)*a) * (1+(m-1)*b) - n*m*c**2)
        if np.isnan(ln_det):
            warnings.warn('Correlation matrix is singular for m={}, n={}, a={}, b={} and c={}.'.format(m, n, a, b, c))
            ln_det = np.inf
        self.last_ln_det = ln_det
        
        ## calculate diff.T * covariance_matrix.I * diff
        diff_sum = np.matrix(diff_sum).T
#         diff_quad_sum = np.matrix(diff_quad_sum).T
        
        A = np.matrix([[a, c], [c, b]])
        W = np.matrix([[1-a, 0], [0, 1-b]])
        D = np.matrix([[n, 0], [0, m]])
#         H = W * A.I * W + D * W
#         product_value = diff_quad_sum.T * W.I * diff_quad_sum - diff_sum.T * H.I * diff_sum
        H = W + D * A
        
#         product_value = diff_quad_sum.T * W.I * diff_quad_sum - diff_sum.T * W.I * A * H.I * diff_sum
        product_value = - diff_sum.T * W.I * A * H.I * diff_sum
        product_value = product_value.item()
        product_value += diff_quad_sum[0] / (1-a)
        product_value += diff_quad_sum[1] / (1-b)
        self.last_product_value = product_value
          
        ## calulate function value
        f = ln_det + product_value
        
#         logger.debug('Returning function value for correlation parameters {} with ln_det={} and product_value={}.'.format(correlation_parameters, ln_det, product_value))
        
        return f
    
    
    
    def f_with_opt_cp_for_diff(self, diff_sum, diff_quad_sum):
        f = lambda cp: self.f_for_cp_and_diff(cp, diff_sum, diff_quad_sum)
        last_correlation_parameters = self.last_correlation_parameters
#         x0s = (last_correlation_parameters, (0, 0, 0))
        
#         (opt_correlation_parameters, opt_f) = util.math.optimize.minimize(f, last_correlation_parameters, global_method='basin_hopping', global_iterations=100, bounds=self.correlation_parameters_bounds, ineq_constraints=self.correlation_parameters_ineq_constraint, ineq_constraints_jac=self.correlation_parameters_ineq_constraints_jac)
        (opt_correlation_parameters, opt_f) = util.math.optimize.minimize(f, last_correlation_parameters, bounds=self.correlation_parameters_bounds, global_method='basin_hopping', global_iterations=200, global_stepsize=0.05, global_stepsize_update_interval=20)
        
        self.last_correlation_parameters = opt_correlation_parameters
        
        logger.debug('Returning optimal correlation parameters {} with value {}.'.format(opt_correlation_parameters, opt_f))
        
        return opt_f
    
    
    
    
    def f_with_opt_cp_for_model_parameters(self, model_parameters):
        from .constants import COST_FUNCTION_CORRELATION_PARAMETER_FILENAME
        
        ## calculate diff norms
        model_f = self.get_model_f(model_parameters)
        values = self.values
        deviation = self.deviation
        
        tracer_dim = 2
        diff_sum = np.empty(tracer_dim)
        diff_quad_sum = np.empty(tracer_dim)
        
        for i in range(tracer_dim):
            diff = (values[i] - model_f[i]) / deviation[i]
            diff_sum[i] = np.sum(diff)
            diff_quad_sum[i] = np.sum(diff**2)
        
        ## calulate function value
        f = self.f_with_opt_cp_for_diff(diff_sum, diff_quad_sum)
        
        self.save_file(model_parameters, COST_FUNCTION_CORRELATION_PARAMETER_FILENAME, self.last_correlation_parameters)
        
        return f
    
    
    
    def df_with_opt_cp_for_model_parameters(self, model_parameters):
        ## calculate diff norms and its derivatives
        model_f = self.get_model_f(model_parameters)
        model_df = self.get_model_df(model_parameters)
        values = self.values
        deviation = self.deviation
        
        tracer_dim = len(values)
        diff_sum = np.empty(tracer_dim)
        diff_quad_sum = np.empty(tracer_dim)
        p_dim = len(model_parameters)
        d_diff_sum = np.empty([tracer_dim, p_dim])
        d_diff_quad_sum = np.empty([tracer_dim, p_dim])
        
        for i in range(tracer_dim):
            diff = (values[i] - model_f[i]) / deviation[i]
            diff_sum[i] = np.sum(diff)
            diff_quad_sum[i] = np.sum(diff**2)
            for j in range(p_dim):
                d_diff_sum[i, j] = - np.sum(model_df[i][j] / deviation[i])
                d_diff_quad_sum[i, j] = - 2 * np.sum((values[i] - model_f[i]) * model_df[i][j] / deviation[i]**2)
        
        ## calculate function values and its derivatives
        f_p = self.f_with_opt_cp_for_diff(diff_sum, diff_quad_sum)
        d1_f_p = util.math.optimize.finite_differences(lambda diff_sum:self.f_with_opt_cp_for_diff(diff_sum, diff_quad_sum), diff_sum, f_x=f_p, bounds=None, accuracy_order=1)
        d2_f_p = util.math.optimize.finite_differences(lambda diff_quad_sum:self.f_with_opt_cp_for_diff(diff_sum, diff_quad_sum), diff_quad_sum, f_x=f_p, bounds=((0, np.inf),)*2, accuracy_order=1)
        
        ## compose derivative
        d_f_p = np.matrix(d1_f_p) * np.matrix(d_diff_sum) + np.matrix(d2_f_p) * np.matrix(d_diff_quad_sum)
        d_f_p = np.array(d_f_p.flat)
        
        return d_f_p;
    
    
    def calculate_f(self, parameters):
        f = self.f_with_opt_cp_for_model_parameters(parameters)
        f_normalized = self.last_product_value * self.normalization_factor
        return (f, f_normalized)
    
    
    def calculate_df(self, parameters):
        df = self.df_with_opt_cp_for_model_parameters(parameters)
        return df







class Family:
    
    def __init__(self, main_member_class, member_classes, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        
        logger.debug('Initiating cost function family with main member {} and members {}.'.format(main_member_class, member_classes))
        
        if main_member_class not in member_classes:
            raise ValueError('The main member class has to be in {}, but its {}.'.format(member_classes, main_member_class))
        
        self.main_member = main_member_class(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file)
        
        family = []
        for member_class in member_classes:
            if member_class is not main_member_class:
                family.append(member_class(years, tolerance, combination, time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file))
        
        self.family = family
    
    
    def f(self, parameters):
        main_member = self.main_member
        main_member_f = main_member.f(parameters)
        last_parameters_f = main_member.last_parameters_f
        last_model_f = main_member.last_model_f
        last_interpolator = main_member.model._interpolator_cached
        
        for member in self.family:
            if last_model_f is not None:
                member.last_parameters_f = last_parameters_f
                member.last_model_f = last_model_f
            
            if member.model._interpolator_cached is None:
                member.model._interpolator_cached = last_interpolator
                
            member.f(parameters)
            
            if last_model_f is None:
                last_parameters_f = member.last_parameters_f
                last_model_f = member.last_model_f
            
            if last_interpolator is None:
                last_interpolator = member.model._interpolator_cached
        
        return main_member_f
    
    
    def df(self, parameters):
        main_member = self.main_member
        main_member_df = main_member.df(parameters)
        last_parameters_df = main_member.last_parameters_df
        last_model_df = main_member.last_model_df
        last_interpolator = main_member.model._interpolator_cached
        
        for member in self.family:
            if last_model_df is not None:
                member.last_parameters_df = last_parameters_df
                member.last_model_df = last_model_df
            
            if member.model._interpolator_cached is None:
                member.model._interpolator_cached = last_interpolator
            
            member.df(parameters)
            
            if last_model_df is None:
                last_parameters_df = member.last_parameters_df
                last_model_df = member.last_model_df
            
            if last_interpolator is None:
                last_interpolator = member.model._interpolator_cached
        
        return main_member_df



class WOA_Family(Family):
    
    def __init__(self, main_member_class, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        member_classes = (WOA_OLS, WOA_WLS)
        super().__init__(main_member_class, member_classes, years=years, tolerance=tolerance, combination=combination, time_step=time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file)



class WOD_Family(Family):
    
    def __init__(self, main_member_class, years, tolerance=0, combination='and', time_step=1, df_accuracy_order=1, job_nodes_max_file=None):
        member_classes = (WOD_OLS, WOD_WLS, WOD_GLS)
        super().__init__(main_member_class, member_classes, years=years, tolerance=tolerance, combination=combination, time_step=time_step, df_accuracy_order=df_accuracy_order, job_nodes_max_file=job_nodes_max_file)